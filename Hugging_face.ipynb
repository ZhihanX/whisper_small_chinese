{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ol40dswkjPv"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install transformer\n",
        "!pip install yt_dlp\n",
        "!pip install gradio==3.38.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVDddq4_komY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import gradio as gr\n",
        "import yt_dlp as youtube_dl\n",
        "from transformers import pipeline\n",
        "from transformers.pipelines.audio_utils import ffmpeg_read\n",
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "MODEL_NAME = \"PatrickML/whisper_small_hyper\"\n",
        "BATCH_SIZE = 16\n",
        "FILE_LIMIT_MB = 1000\n",
        "YT_LENGTH_LIMIT_S = 3600  # limit to 1 hour Video files\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "pipe = pipeline(\n",
        "    task=\"automatic-speech-recognition\",\n",
        "    model=MODEL_NAME,\n",
        "    chunk_length_s=30,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def transcribe(inputs, task):\n",
        "    if inputs is None:\n",
        "        raise gr.Error(\"No audio file submitted! Please upload or record an audio file before submitting your request.\")\n",
        "\n",
        "    text = pipe(inputs, batch_size=BATCH_SIZE, generate_kwargs={\"task\": task}, return_timestamps=True)[\"text\"]\n",
        "    return  text\n",
        "\n",
        "\n",
        "\n",
        "def _return_yt_html_embed(yt_url):\n",
        "    video_id = yt_url.split(\"?v=\")[-1]\n",
        "    HTML_str = (\n",
        "        f'<center> <iframe width=\"500\" height=\"320\" src=\"https://www.youtube.com/embed/{video_id}\"> </iframe>'\n",
        "        \" </center>\"\n",
        "    )\n",
        "    return HTML_str\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def download_yt_audio(yt_url, filename):\n",
        "    info_loader = youtube_dl.YoutubeDL()\n",
        "\n",
        "    try:\n",
        "        info = info_loader.extract_info(yt_url, download=False)\n",
        "    except youtube_dl.utils.DownloadError as err:\n",
        "        raise gr.Error(str(err))\n",
        "\n",
        "    file_length = info[\"duration_string\"]\n",
        "    file_h_m_s = file_length.split(\":\")\n",
        "    file_h_m_s = [int(sub_length) for sub_length in file_h_m_s]\n",
        "\n",
        "    if len(file_h_m_s) == 1:\n",
        "        file_h_m_s.insert(0, 0)\n",
        "    if len(file_h_m_s) == 2:\n",
        "        file_h_m_s.insert(0, 0)\n",
        "    file_length_s = file_h_m_s[0] * 3600 + file_h_m_s[1] * 60 + file_h_m_s[2]\n",
        "\n",
        "    if file_length_s > YT_LENGTH_LIMIT_S:\n",
        "        yt_length_limit_hms = time.strftime(\"%HH:%MM:%SS\", time.gmtime(YT_LENGTH_LIMIT_S))\n",
        "        file_length_hms = time.strftime(\"%HH:%MM:%SS\", time.gmtime(file_length_s))\n",
        "        raise gr.Error(f\"Maximum Url video length is {yt_length_limit_hms}, got {file_length_hms} Url video.\")\n",
        "\n",
        "    ydl_opts = {\"outtmpl\": filename, \"format\": \"worstvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best\"}\n",
        "\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            ydl.download([yt_url])\n",
        "        except youtube_dl.utils.ExtractorError as err:\n",
        "            raise gr.Error(str(err))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def yt_transcribe(yt_url, task, max_filesize=75.0):\n",
        "    html_embed_str = _return_yt_html_embed(yt_url)\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "        filepath = os.path.join(tmpdirname, \"video.mp4\")\n",
        "        download_yt_audio(yt_url, filepath)\n",
        "        with open(filepath, \"rb\") as f:\n",
        "            inputs = f.read()\n",
        "\n",
        "    inputs = ffmpeg_read(inputs, pipe.feature_extractor.sampling_rate)\n",
        "    inputs = {\"array\": inputs, \"sampling_rate\": pipe.feature_extractor.sampling_rate}\n",
        "\n",
        "    text = pipe(inputs, batch_size=BATCH_SIZE, generate_kwargs={\"task\": task}, return_timestamps=True)[\"text\"]\n",
        "\n",
        "    return html_embed_str, text\n",
        "\n",
        "\n",
        "\n",
        "demo = gr.Blocks()\n",
        "\n",
        "\n",
        "\n",
        "mf_transcribe = gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\", optional=True),\n",
        "        gr.inputs.Radio([\"transcribe\"], label=\"Task\", default=\"transcribe\"),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    # layout=\"vertical\",\n",
        "    theme=\"hugging face\",\n",
        "    title=\"Whisper Small Fine tune: Transcribe Audio\",\n",
        "    description=(\n",
        "        \"Transcribe long-form microphone or audio inputs with the click of a button! Demo uses\"\n",
        "        f\" [{MODEL_NAME}](https://huggingface.co/{MODEL_NAME})\"\n",
        "        \" of arbitrary length.\"\n",
        "    ),\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "yt_transcribe = gr.Interface(\n",
        "    fn=yt_transcribe,\n",
        "    inputs=[\n",
        "        gr.inputs.Textbox(lines=1, placeholder=\"Paste the URL to a video here\", label=\"URL\"),\n",
        "        gr.inputs.Radio([\"transcribe\",], label=\"Task\", default=\"transcribe\")\n",
        "    ],\n",
        "    outputs=[\"html\", \"text\"],\n",
        "    layout=\"horizontal\",\n",
        "    theme=\"huggingface\",\n",
        "    title=\"Whisper Small Fine tune: Transcribe Video\",\n",
        "    description=(\n",
        "        \"Transcribe long-form videos with the click of a button! Demo uses\"\n",
        "        f\" [{MODEL_NAME}](https://huggingface.co/{MODEL_NAME}) \"\n",
        "        \" arbitrary length.\"\n",
        "    ),\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "file_transcribe = gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"upload\", type=\"filepath\", optional=True, label=\"Audio file\"),\n",
        "        gr.inputs.Radio([\"transcribe\"], label=\"Task\", default=\"transcribe\"),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    layout=\"horizontal\",\n",
        "    theme=\"huggingface\",\n",
        "    title=\"Whisper Small Fine tune: Transcribe Audio\",\n",
        "    description=(\n",
        "        \"Transcribe long-form microphone or audio inputs with the click of a button! Demo uses the\"\n",
        "        f\"[{MODEL_NAME}](https://huggingface.co/{MODEL_NAME})\"\n",
        "        \" of arbitrary length.\"\n",
        "    ),\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with demo:\n",
        "    gr.TabbedInterface([mf_transcribe, yt_transcribe,file_transcribe ], [\"Microphone\", \"Url\" ,\"Audio file\"])\n",
        "\n",
        "demo.launch(enable_queue=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
